\documentclass[DM,lsstdraft,toc]{lsstdoc}
\usepackage{graphicx}
\usepackage{url}
\usepackage{latexsym}
\usepackage{color}
% black, blue, brown, cyan, darkgray, gray, green, lightgray, lime, magenta, blue, orange, pink, purple, red, teal, violet, white, yellow.
\usepackage{enumitem}
\usepackage{esvect}

\title[Detection Efficiencies]{Options for Generating Detection Efficiencies for {\tt DIASources}}

\author{M.~L.~Graham et al., and the DM SST}

\setDocRef{DMTN-TBD}
\date{\today}
\setDocUpstreamLocation{\url{https://github.com/lsst-dm/dmtn-tbd}}

\setDocAbstract{ \textcolor{red}{MLG: THIS DOC IS A DRAFT IN PROGRESS. DO NOT CITE.}\\ 
In this study we explore and evaluate options for the generation of detection efficiencies for difference-image point sources detected by Difference Imaging Analysis (DIA).
We review the LSST requirements on characterizing DIA in terms of completeness and purity of detected sources, and compare this with the anticipated needs of the scientific community.
The role of injecting and recovering fake point-sources as a means to generating detection efficiencies is given particular attention.}

\setDocChangeRecord{%
\addtohist{0}{2018-11-01}{Internal working document.}{Melissa Graham}
%\addtohist{2}{yyyy-mm-dd}{Future changes}{Future person}
}

\begin{document}

\maketitle

% CITATION EXAMPLES
% \verb|\citellp|: \citellp{LPM-17, LSE-30} \\
% \verb|\citell|: (SRD; \citell{LPM-17,LSE-29}) \\
% \verb|\citep[][]|: \citep[e.g.,][are interesting]{LPM-17,LSE-29} \\
% \verb|\cite|: \cite{LPM-17,LSE-29}
% \citeds{LSE-163}, \citedsp{LSE-163}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Introduction} \label{sec:intro}

% This DMTN is associated with JIRA Ticket DM-12584.

A detection efficiency is the probability that a source of a given brightness is detected, given that it exists. In other words, the fraction of all real sources of a given brightness that are detected by a survey. This document deals with measuring the detection efficiency for point-sources in a difference image. Difference images are produced by subtracting a template image from a direct image. Template images are not just any other image of the same field: they are generated by stacking a set of previous images to both (1) increase depth and (2) "remove" the flux of any transient or moving objects and "standardize" the flux of variable objects. Point-sources in a difference image are thus the time-changing components of transient and variable objects. All scientific analyses that involve population studies or occurrence rates of transient, variable, or moving objects discovered via difference imaging analysis (DIA) require knowing the survey's detection efficiency for point-sources\footnote{We consider the detection efficiencies of extended difference-image sources (e.g., light echoes, trailed moving objects) to be beyond the scope of this study.} in the difference images. Any scientific question which asks {\it "How often?"} or {\it "How many?"} with respect to astrophysical phenomena falls into this category of analyses. At all times in this work when we refer generically to a {\it detection efficiency} we mean {\it the detection efficiency of point-sources in difference images}. The shorthand term used by LSST for a source detected via difference imaging analysis is a {\tt DIASource}. 

The detection efficiency can be represented as $\eta(m)$, where $m$ is the apparent magnitude of the time-changing component with respect to the template image, and $\eta$ is a value between $0$ and $1$ that represents the probability that the source would be detected in the difference image. In practice, $\eta$ depends on more than just $m$, and can be a function of the parameters ($\vv{P}$) listed in Table \ref{tab:eta_pars}. An accurate measure of $\eta(\vv{P})$ for every pixel of every difference image is technologically unfeasible for most modern imaging surveys, and especially so for the LSST. Instead, it will be necessary to build an analytic model for $\eta$ as a function of the relevant parameters $\vv{P}$ --- some of which may have correlated effects --- which can then be applied to any location in any image. {\bf The topic of this study is the generation of a detection efficiency matrix, $\eta(\vv{P})$, as an LSST DIA data product.}

\begin{table}[h]
\begin{center}
\begin{footnotesize}
\caption[]{A description of the image and source parameters ($\vv{P}$) that can affect the detection efficiency ($\eta$) of point-sources in a difference image (per filter).}
\label{tab:eta_pars}
\setlength{\extrarowheight}{5pt}
\begin{tabular}{|p{3.1cm}|p{12cm}|}
\hline
{\bf Parameter} & {\bf Description} \\
\hline
Apparent Magnitude & Typically, $\eta$ decreases for fainter objects (and brighter objects due to saturation). \\
\hline
Surface Brightness & Typically, $\eta$ decreases for objects embedded in brighter host galaxies. \\
\hline
Static-Source Offset & Sometimes, $\eta$ decreases for objects that are near (i.e., overlap the point-spread function of) static sources (e.g., stars, galaxy cores, especially if cuspy in profile). \\
\hline
CCD Location & With some instruments, $\eta$ decreases near the CCD edges due to distortion. \\
\hline
Image FWHM & The value of $\eta$ can decrease for extreme FWHM differences from the template (i.e., very good or very poor seeing). \\
\hline
Image Airmass & LSST images will experience differential chromatic refraction which affects image subtraction \citedsp{DMTN-037}, and thus potentially also $\eta$. \\
\hline
Sky Brightness & Typically, $\eta$ decreases when the sky background is bright or has a strong gradient (e.g., during twilight, near the moon). \\
\hline
Sky Cloud Cover & Extinction will affect $\eta$ by degrading the image magnitude limit. \\
\hline
\end{tabular}
\end{footnotesize}
\end{center}
\end{table}

\subsection{Study Overview}
\begin{itemize}
\item \S~\ref{sec:sci} contains a primer on the concepts related to detection efficiencies, and an overview of several science goals that rely on them, with examples of methods for generating and applying detection efficiencies from a selection of recent time-domain surveys. 
\item \S~\ref{sec:docs} reviews the LSST Data Management System's (DMS) literature and highlight existing plans, policies, requirements, and specifications related to the generation of LSST survey detection efficiencies. 
\item \S~\ref{sec:DE} presents and evaluates various options for how the DMS could provide detection efficiencies as a data product. 
\item \S~\ref{sec:opts_fakes} outlines several techniques for injecting fake point-source variability into images.
\end{itemize}

\subsection{Summary of Study Findings}
\begin{enumerate}
\item It would be most scientifically useful -- with only a small increase in scope -- to ensure that the fake injection of point sources used to characterize the {\tt DIASouce} spuriousness parameter fill the parameter space needed for scientific analyses involving detection efficiencies, and to provide the detection efficiency matrix $\eta(\vv{P})$.
\item It would also be scientifically useful to make catalogs of the injected fakes available to users, to enable them to build detection efficiency matrices, $\eta(\vv{P})$, for their science goals.
\item Further study (simulations) will be needed to identify the optimal mode of fake injection (e.g., modeling the point-spread function or using isolated stars), and the full set of parameters $\vv{P}$ for which $\eta$ should be determined.
\item Soliciting feedback and science use-cases from the community should be considered as a means to prioritize and make decisions regarding the above.
\end{enumerate}



% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Scientific Motivation and Use-Cases for Detection Efficiencies}\label{sec:sci}

In \S~\ref{ssec:sci_rb} we introduce the concepts of completeness, purity, and spuriousness for difference-image sources in imaging surveys, and how they are connected to detection efficiency. As described in \S~\ref{sec:docs}, the LSST DMS will characterize {\tt DIASource} completeness and purity as a function of source spuriousness and signal-to-noise ratio (which correlates with source apparent magnitude) --- likely using an analysis of injected fake sources --- but not necessarily as a function of all parameters $\vv{P}$ listed in Table \ref{tab:eta_pars}. The latter is essential for generating the detection efficiencies for a given population of astronomical objects, which is described in \S~\ref{ssec:sci_trans} to \ref{ssec:sci_move}. We discuss a cross-section of science use-cases for detection efficiencies in the fields of transients, AGN, variable stars, and moving objects that are similar to science pursued with LSST data. 

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Completeness, Purity, and Spuriousness}\label{ssec:sci_rb}

All sources in a survey's difference image are either: \\
\hspace*{10mm} {\bf real} -- caused by a true astrophysical event, or \\
\hspace*{10mm} {\bf bogus} -- an artifact of the telescope hardware or image processing. \\ 
Incompletely removed cosmic rays are considered an artifact, bogus, in this context. 

The {\bf spuriousness} ($\mathcal{S}$) of a source is a value, typically between $0$ and $1$, which represents the probability that a source is real (values closer to $1$) or bogus (values closer to $0$). The spuriousness is sometimes also called the {\it real/bogus score}, and is often determined by machine learning on many sources that were pre-classified as real or bogus. A {\bf spuriousness threshold} ($\tau_{\mathcal{S}}$) is applied to classify the sources deemed likely to be real as {\it detected} by the survey. By raising and lowering the value of $\tau_{\mathcal{S}}$ between $1$ and $0$, the set of detections can be made either more pure (higher $\tau_{\mathcal{S}}$) or more complete (lower $\tau_{\mathcal{S}}$). 

The following definitions categorize the possible states of all real (astrophysical) and bogus (artifact) sources, where "positive" means "detected" and "negative" means "not detected": \\
\hspace*{10mm} {\bf True Positive} ($\mathit{TP}$) -- an astrophysical source that was detected. \\
\hspace*{10mm} {\bf False Positive} ($\mathit{FP}$) -- an artifact that was detected. \\
\hspace*{10mm} {\bf True Negative} ($\mathit{TN}$) -- an artifact that was not detected. \\
\hspace*{10mm} {\bf False Negative} ($\mathit{FN}$) -- an astrophysical source that was not detected. 

The survey's {\bf completeness} ($\mathcal{C}$) is the fraction of all real sources that are detected, which we will here call the true positive rate, $\mathit{TPR} = \frac{\mathit{TP}}{\mathit{TP}+\mathit{FN}}$. The $\mathit{TPR}$ is equivalent to the detection efficiency, $\eta$, which was introduced in Section \ref{sec:intro}. The missed detection rate is the fraction of all real sources that were not detected, $\mathit{MDR} = 1 - \mathit{TPR} = \frac{\mathit{FN}}{\mathit{TP}+\mathit{FN}}$. 

The survey's {\bf purity} ($\mathcal{P}$) is the fraction of all detections that are real astrophysical sources, $\frac{\mathit{TP}}{\mathit{TP}+\mathit{FP}}$. This is also called the {\it precision} or the {\it positive predictive value} ($\mathit{PPV}$) of the survey. The false positive rate\footnote{Note that in some cases the false positive rate is defined as the fraction of all artifacts that are detected, $\mathit{FPR} = \frac{\mathit{FP}}{\mathit{TN}+\mathit{FP}}$, and not the fraction of all detections that are artifacts, $\frac{\mathit{FP}}{\mathit{TP}+\mathit{FP}}$, as we have used here.} is then $\mathit{FPR} = 1 - \mathit{PPV} = \frac{\mathit{FP}}{\mathit{TP}+\mathit{FP}}$. 

\begin{figure}
\begin{center}
\includegraphics[width=8cm,trim={0cm 0cm 0cm 0cm}, clip]{figures/Brink_etal_2013_Fig3.jpg}
\includegraphics[width=8cm,trim={0cm 0cm 0cm 0cm}, clip]{figures/Brink_etal_2013_Fig7.jpg}
\caption{{\it Left:} An example of the relationship between the false positive rate ($\mathit{FPR}$; purity) {\it vs.} the missed detection rate ($\mathit{MDR}$; completeness) for different types of source classification algorithms considered by the Palomar Transient Factory \citep{2013MNRAS.435.1047B}. {\it Right:} The relationship between $\mathit{FPR}$ and $\mathit{MDR}$ for the RB2 (real-bogus version 2) classifier (blue line) developed by the PTF and introduced in \cite{2013MNRAS.435.1047B}. Dashed lines show how $\mathit{FPR}=0.01$ is achieved with a spuriousness (real-bogus score value) threshold of $\tau=0.53$, which results in $\mathit{MDR}=0.077$. \label{fig:comp_pure}}
\end{center}
\end{figure}

The relationship between the completeness and purity of a sample of {\it detections} can be traced out by varying $\tau_{\mathcal{S}}$. In Figure \ref{fig:comp_pure} we show an example of the relationship between the false positive rate ($\mathit{FPR}$; purity) {\it vs.} the missed detection rate ($\mathit{MDR}$; completeness) for different types of source classification algorithms from the Palomar Transient Factory \citep[PTF;][]{2013MNRAS.435.1047B}. This relationship is formally known as the Receiver Operating Characteristic (ROC) curve when it is plotted as the true positive rate {\it vs.} the false positive rate. 

Characterizing the completeness and purity of a survey requires knowing, {\em a priori}, which of the detected sources are truly real ($\mathit{TP}$), and how many real sources there are in total ($\mathit{TP}+\mathit{FN}$). This is only possible in two scenarios: (1) if co-temporal imaging data of superior quality is in hand (i.e., ``truth" images), or (2) if sources have been simulated and added to the data. However, co-temporal imaging data of superior quality almost never exists (i.e., it is inefficient to duplicate data). Typically, the simulation and injection of fake sources are used to generate a sample of ``real" sources, so that the completeness ($\mathcal{C}$, $\mathit{TPR}$, $\mathit{MDR}$) and purity ($\mathcal{P}$, $\mathit{PPV}$, $\mathit{FPR}$) of the survey and its data processing pipelines can be characterized. 

In order to identify a set of {\it detections} with the completeness and purity required for a given scientific analysis, surveys use the characterized relationship between $\mathcal{C}$, $\mathcal{P}$, and $\mathcal{S}$ to define and impose a spuriousness threshold $\tau_{\mathcal{S}}$ on the full sample.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Transients}\label{ssec:sci_trans}

Transient events such as stellar explosions (supernovae, kilonovae) and tidal disruption events (stars destroyed by close passage to a supermassive black hole) occur once and do not repeat. Since most transient progenitors are stars, they are most often found in high surface brightness environments (i.e., galaxies; their spatial distribution ``follows the light") and require difference imaging in order to be discovered, and thus detection efficiencies in order to characterize their occurrence rates. For example, transient occurrence rates as a function of environment can constrain their progenitor star characteristics, which requires that detection biases be well known, as does understanding selection biases in transient samples (e.g., when using Type Ia supernova as cosmological standard candles). 

The following describe four past transient surveys and how they measured their transient detection efficiencies. \textcolor{red}{\bf MLG: The following paragraphs could use a good pruning.}

{\bf Sloan Digital Sky Survey II (SDSS-II) ---} In order to calculate the occurrence rates of Type Ia supernovae (SNe\,Ia) from the SDSS-II, \cite{2008AJ....135..348S} generated a realistic sample of SNe\,Ia and injected fake point sources into the images as part of the real-time data processing pipeline to discover SNe\,Ia. Additional simulations to evaluate on how often the fakes were recovered by the end-to-end SN\,Ia discovery pipeline were then required to evaluate how assumptions about the simulated population (e.g., the distribution of light curve stretches) contributed to the final uncertainty in the derived rates \citep{2008ApJ...682..262D}. The final form of their derived detection efficiency for SNe\,Ia is $\epsilon(z) = (0.78 \pm 0.01) + (-0.13 \pm 0.14)z$, within which is captured assumptions about the true relative fraction of each SN\,Ia subtype, such as the under/over-luminous 91bg/91T-likes \citep{2008ApJ...682..262D}. The detection efficiency, $\epsilon$, contributes to the final volumetric rate, $r_V = N / \widetilde{VT\epsilon}$, where $N$ is the number of SNe\,Ia detected, and $\widetilde{VT\epsilon}$ is the product of the effective survey volume, time, and detection efficiency.

{\bf Dark Energy Survey (DES) ---} The DES also injected fake sources into their live data, which was run through their real-time {\tt DiffImg} pipeline used to detect transients \cite{2015AJ....150..172K}. Like the method used by SDSS-II, this process also starts with simulating a realistic sample of SNe\,Ia, with parameters such as light curve stretch, host offset, and subtype drawn from established underlying distributions. The DES SN survey team also uses a Monte Carlo simulation of many more SN light curves, combined with the detection efficiencies for their fakes, to determine the SN\,Ia detection efficiency as a function of redshift \cite{2015AJ....150..172K}.
% The DES real/bogus algorithm an pipeline are described by Goldstein et al. 2015:
% http://adsabs.harvard.edu/abs/2015AJ....150...82G

{\bf A Canada-France-Hawaii Telescope (CFHT) Cluster Survey ---} Compared to SDSS-II and DES, a slightly different approach to the SN\,Ia rate calculation is taken by \cite{2012ApJ...746..163S} for a survey which is based on monthly imaging with the MegaCam 1 square degree imager on CFHT. Although SN detections were made in real-time, the fake injection was not done promptly. Instead, fakes were implanted into a representative subset of their images, and detection efficiencies (in this case, represented by $\eta$) were calculated as a function of the relevant parameters for this survey: apparent magnitude, image quality, host offset, and location in the focal plane. As presented in \cite{2012ApJ...746..163S}, the rate of Type Ia supernovae, $R_{\rm Ia}$, per unit stellar mass $\rm SNe\, M_{\odot}^{-1}$, is given by $R_{\rm Ia} = (N_{\rm Ia} / C_{\rm spec}) / ( \sum_{j=1}^{j=N_{\rm img}} \Delta t_j Mj )$, where $N_{\rm Ia}$ is the number of SNe\,Ia discovered in the survey and $C_{\rm spec}$ is the fraction of discovered SNe that were spectroscopically confirmed (determined separately). In the denominator, the sum is over all images of the survey, where $M_j$ is the total stellar mass within the image and $\Delta t_j$ is the control time of that image: $\Delta t = \int_{t_1}^{t_2} \eta(m(t)) dt$, where $m(t)$ is a SN's light curve (apparent magnitude, $m$, as a function of time, $t$), $\eta$ is the detection efficiency for image $j$, and the integration limits are the survey's temporal boundaries. The control time of a given image for a given SN light curve must also account for the probability that the light curve was detected in a prior image. For this particular CFHT program -- a $\sim$monthly survey of SNe\,Ia at low-redshift -- at most the two previous images need be considered. Therefore the detection efficiency $\eta$ used in the above equation was: $\eta = \eta_j - \eta_j \eta_{(j-1)} - \eta_j \eta_{(j-2)} - \eta_j \eta_{(j-1)} \eta_{(j-2)}$. A realistic sample of simulated SN\,Ia light curves, $m(t)$, is then used to calculate a set of $R_{\rm Ia}$, and the median and $1\sigma$ errors are quoted as the final derived SN\,Ia rates per unit stellar mass. Once the detection efficiencies, $\eta$, are calculated, they can be applied to {\it any simulated set of light curves} for which an event rate is desired; for example, see the rates of Type II supernovae (SNe\,II) presented for the same survey in \cite{2012ApJ...753...68G}.

% Frohmaier uses stars from the field, not a simulated PSF: "clone-stamping".
% Frohmaier 2019 details: r_v(z) = (1/V deltaT) sum_{i=1}^N (1+z_i) / epsilon_i
% r_v(z) = volumetric rate of SNeIa at redshift z
% V = volume
% delta T = survey time
% sum over the number of SNeIa in the final sample
% (1+z_i) = cosmological time dilation factor
% epsilon_i = "detection efficiencies of each object"
% but note that epsilon != eta, rather epsilon is built from eta
% a large sample of SNeIa with realistic intrinsic properties are simulated, planted in the data, and then recovered, and then a grid of recovery fractions as a function of SNIa intrinsic properties and redshift is created, and those are the epsilons assigned to detected SNeIa
{\bf Palomar Transient Factory (PTF) ---} The PTF covered $8000$ square degrees with a three-to-five day cadence, generating over $1$ $\rm PB$ of data. As detailed by \cite{2017ApJS..230....4F}, inserting fake sources into all of these images was both impractical and unnecessary. Instead, they choose a single representative {\it field} and planted fake sources in all images of that field. The fakes are given a uniform distribution in apparent magnitude, distributed in each image such that most of them are located within a galaxy, and then the PTF detection efficiencies are determined as a function of the PSF apparent magnitude, the local surface brightness, and image parameters such as FWHM, airmass, moon illumination fraction, and sky background. These detection efficiencies were used to derive the volumetric rate of normal SNe\,Ia \citep{2019MNRAS.tmp..772F}, of Ca-rich transients by \cite{2018ApJ...858...50F}, and of tidal disruption events (TDEs) by \cite{2018ApJS..238...15H}, but we note also that some rates analyses for TDEs have used aperture photometry and not difference imaging (and thus did not need fake injection for detection efficiencies, \citealt{2016MNRAS.455.2918H}; see also \S~\ref{ssec:sci_agn}).  

{\bf Summary --} These four surveys have either inserted fakes into all of their live images (SDSS-II and DES), or inserted fakes into a representative set of images at a later time (CFHT and PTF), to ensure that detection efficiencies can be determined for the full range of image parameters (e.g., those listed in Table \ref{tab:eta_pars}). In all cases, the fakes were simulated with parameter distributions (e.g., brightness, location) that roughly mimic the real astrophysical objects of interest for each particular survey (mostly supernovae, for the above examples). Then, as a part of their scientific analyses, they simulate light curves for the specific transients of interest, and the detection efficiencies derived from the fake injection process are applied to them. Therefore, to best serve a broad section of the transient community, the simulated population of fake sources injected need only be representative of true astrophysical sources in a bulk sense, in terms of their brightness and location (i.e., plant more faint sources than bright, and more in high surface-brightness areas than isolated regions; see also Table \ref{tab:eta_pars}). The simulated fakes do not need to accurately represent astrophysical transient types, colors, redshifts, durations, light curves, etc., or planted in sequential images in a correlated way to represent real light curves. That aspect of the analysis is best left to the user, who will perform, e.g., Monte-Carlo simulations of intrinsic light curves for their object of interest, and combine them with the LSST-derived detection efficiencies in order to derive the survey's completeness for that object class and, e.g., incorporate it into their population study or rates calculations.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Active Galactic Nuclei}\label{ssec:sci_agn}

Active Galactic Nuclei (AGN) are powered by a supermassive black hole in the center of a galaxy, surrounded by a gas disk. Their energy output is non-thermal emission from X-ray through to mid-infrared, including emission lines in the optical spectrum, and many (or most) AGN exhibit optical variability. As such, they appear as a variable point source in the cores of galaxies. Although both AGN and TDE occur in the core of galaxies, their analysis methodologies have been different. Studies of AGN typically use aperture photometry on direct images because it is desirable to have the {\it entire} flux of the AGN's point-source, not just the flux in its variable component. However, for TDE, the desire is for the flux from the TDE alone, with any underlying point source from the galaxy removed, and so difference imaging is needed for TDE studies.

% The first to use variability to select AGN was Sarajedini et al. 2003; an two-epoch HST survey.
AGN samples have typically identified using spectroscopic emission lines, optical colors, or by looking for excesses of radio, X-ray, or mid-infrared emission, but selection by optical variability is also an option and in particular it may be better at including low-luminosity AGN, as described by \cite[e.g.,][]{2008A&A...488...73T,2010ApJ...723..737V}. The detection method of \cite{2008A&A...488...73T} uses image subtraction for the initial detection of AGN candidates, mainly because difference imaging was already done to find supernovae in the survey. Aperture photometry is then performed on the candidates, and a variability threshold applied to form their final sample for spectroscopic follow-up. \cite{2010ApJ...723..737V} skip the difference imaging step and use aperture photometry and a statistical analysis true variability to identify AGN. Neither use the injection of fake point-sources to evaluate their detection efficiencies, and instead use objects with spectra and/or X-ray detections to estimate their completeness. % De Cicco et al. 2015 is very similar to Trevese, done in the VST-SUDARE/VOICE survey for SNe.

However, characterizing the sample selection function for AGN identified by optical variability with spectra or X-ray detections may well not be possible in the LSST era, when optical variability will become a more efficient and prolific way to discover AGN \cite[e.g.,][]{2014ApJ...782...37C}, and will be able to generate significantly larger, lower-luminosity, and/or higher-redshift samples for which spectroscopic confirmation is more difficult. With this in mind, a population of fake injected transients to characterize the difference-image detection efficiency of point sources in galaxy cores may well be needed by the LSST AGN community. Since SNe also occur in the cores of galaxies \citep[e.g.,][]{2009A&A...507L..17P,2012ApJ...744L..19K}, and quantifying the missed detection rate in the shrouded cores of, e.g., luminous infrared galaxies (LIRGs) remains an open problem, it would be scientifically beneficial to have injected fakes liberally distributed to galaxy cores.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Variable Stars}\label{ssec:sci_varstar}

Here we consider the science goals associated with both intrinsic variability (e.g., RR Lyrae, Cepheids) and extrinsic variability (e.g., eclipsing binaries, exoplanet transits, or microlensing events). In uncrowded fields, using direct images and the total flux is preferable to difference-imaging analysis in scientific studies that aim to identify and characterize variable stars. The reason is the same as it is for AGN: it is desirable to have the {\it entire} flux of the source, not just the variable component with the template's flux subtracted from it.

However, in very crowded fields such as the Galactic plane, identifying variable stars in difference images can be much easier because the difference image is not as (or not at all) crowded, compared to the direct image. For example, the census of variable stars in crowded fields by \cite{2016A&A...588A.128F} does describe how difference imaging is used, but it does not appear that injecting fake sources or deriving detection efficiencies was needed for their analysis. This is similar to studies of microlensing, in which a common methodology is to fit a PSF to every pixel of a difference image, concoct a "light curve", and then statistically assess whether it is consistent with the expected shape of a microlensing event \cite{2015ApJ...806..161L}\footnote{Although \cite{2015ApJ...806..161L} does mention that detection efficiencies would be used in a paper in preparation.}.

The best technique to simulate variability in real point sources might not be fake injection (see \S~\ref{ssec:opts_fakes_simvar}), since there is already a point source in the template. However, injecting new fake sources in crowded stellar fields might be useful for detection efficiencies for stars which are too faint to have a counterpart in the template, but whose variable component makes them detectable by LSST for a short while. This would apply to e.g., M-dwarf flares (a common contaminant in searches for young SNe) and microlensing events.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Moving Objects}\label{ssec:sci_move}

In epochs of non-detection, being able to obtain the detection efficiency at a predicted location (i.e., as a function of local surface brightness and image qualities) would be a useful quantity for science goals related to moving object populations. The probability of, e.g., a faint asteroid's chance alignment over bright galaxies is small, and so fake injected point sources in empty locations may be more useful for moving object science --- these would be needed to simulate very high-redshift transients, as well. A consideration of whether the injection of trailed sources is scientifically useful is left for other work.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{LSST Requirements and Plans Regarding Detection Efficiencies}\label{sec:docs}

Here we review each of the main requirements documents and highlight items that are related to detection efficiencies, and any mentions of fake injection in particular.

The LSST Science Requirements Document \citedsp{LPM-17}) and the LSST System Requirements Document \citedsp{LSE-29} do not make any statements or put any requirements on the detection efficiencies.

% % % % % % % % % % % % % % % % 
\subsection{Observatory System Specifications (OSS)}\label{ssec:docs_oss}

With respect to Prompt data products, the OSS \citedsp{LSE-30} contains several specifications related to the spuriousness parameter in Section 3.1.5.2 ({\it "Level 1 Data Products"}).
\begin{itemize}
\item To develop\ossreq{0351} a metric to characterize the spuriousness of each detected difference image source. There is a specific note that the performance of this metric be assessed {\it "by insertion and recovery of artificial sources"}. (Section 3.1.5.2.1.7.5). 
\item To estimate\ossreq{0352} the completeness and purity as a function of spuriousness threshold for each visit. This will enable users to choose a spuriousness threshold that delivers a sample with the completeness and purity needed for their science goals. (Section 3.1.5.2.1.7.6).
\item To provide\ossreq{0353}\reqparam{transSampleSNR}\reqparam{transCompletenessMin}\reqparam{transPurityMin} a spuriousness threshold that delivers a sample of difference image sources with signal-to-noise ratio $>6$ which is $90\%$ complete and $95\%$ pure (averaged over all visits). (Section 3.1.5.2.1.7.7).
\item To provide\ossreq{0354}\reqparam{orbitObservationThreshold}\reqparam{mopsCompletenessMin}\reqparam{mopsPurityMin} a spuriousness threshold that delivers a sample of difference image sources with signal-to-noise ratio $>5$ which is $>99\%$ complete and $>50\%$ pure (averaged over one month of visits). (Section 3.1.5.2.1.7.8).
\end{itemize}

Although the above specifications require the observatory to provide, for each visit, metrics and thresholds related to the spuriousness parameter as part of the Prompt data products -- and furthermore indicate that fake injection will be part of the derivation of these metrics and thresholds -- these specifications to not require that the fake injection be done as a part of the Prompt processing pipeline. They do indicate, however, that the spuriousness threshold will have to be parameterized in terms of visit image qualities.

With respect to Data Release data products (e.g., direct and coadded images, reprocessed difference images), the OSS specifies\ossreq{0164} that {\it ``object catalog completeness and reliability shall be determined by the data management system"} as a function of magnitude, for objects such as {\it "supernovae at a range of redshifts"}. The OSS furthermore states that provisions be made to enable completeness calculations of other object types {\it "through injection of synthetic objects into the DM pipelines during the Data Release processing (ie. not part of the live data stream)"} (Section 3.1.5.3.2.9, {\it "Level 2 Data Products"}).

{\bf Summary --} The OSS indicates that simulations of fake sources would be used to meet specifications regarding the provision of a spuriousness parameter for difference-image sources, and the thresholds for completeness and purity related to spuriousness, as a function of visit image qualities. 

%%%MLG: This is sufficiently stated in other places.
% For scientific analyses (e.g., Section \ref{sec:sci}), the detection efficiency (completeness) must additionally be known as a function of the source's context, such as local surface brightness (host galaxy background) or proximity to a bright point source (as listed in Table \ref{tab:eta_pars}. The same fake injection routine which meets the OSS's specifications could potentially also be used to derive detection efficiencies in the full parameter space of Table \ref{tab:eta_pars}.


% % % % % % % % % % % % % % % % 
\subsection{Data Management System Requirements (DMSR)}\label{ssec:docs_dmsr}

The DMSR \citedsp{LSE-61} specifies that Data Management System (DMS) shall produce\dmreq{0097} nightly data quality reports that include, among other items, {\it "detection efficiency for point sources vs. mag for each utilized filter"} (it is not specified whether this applies to both direct and difference images). However, based on this requirement's flow-down\footnote{DMS-REQ-0097 is derived from OSS-REQ-0131, {\it ``Nightly Summary Products"}, which describes how the prompt data products shall include nightly reports that summarize the scientific quality of the data and the performance of the observatory and the DMS.}, the intent of this requirement is to provide a nightly summary of the data's bulk scientific quality and the general performance of the observatory and the DMS, not to provide the scientifically useful detection efficiencies that are the topic of this study. 

The DMSR also specifies\dmreq{0009} that the DMS {\it ``shall provide the ability to inject artificial or simulated data into data to assess ... performance"}, and this is derived in part from OSS requirements 0351, 0353, and 0354 discussed in Section \ref{ssec:docs_oss}.

{\bf Summary --} It is clear that the software for fake injection is a deliverable of the DMS, but the DMSR itself does not contain any formal requirements related to using that software to produce detection efficiencies suitable for scientific analyses. 

% As a side note, \citeds{LSE-61} requires that the range of epochs which may contribute to a template image is limited to no more than 1 year\reqparam{templateMaxTimespan}\dmreq{0280}. \citeds{LDM-151} states that TemplateCoadd images should be within a default $2$ years of the current CalExp image which is about to undergo DIA (Section 3.2.3 of \cite{LDM-151}). Taken together, these statements indicate that during DR reprocessing of the DIA data products, there will be as many templates as there are years of survey, and that the multi-year set of {\tt DIASources} for a given {\tt DIAObject} would be generated {\it multiple templates} instead of using just one for a consistent light curve. This is odd.


% % % % % % % % % % % % % % % % 
\subsection{Data Products Definitions Document (DPDD)}\label{ssec:docs_dpdd}

The DPDD \citedsp{LSE-163} does not define a specific data product that represents the difference imaging analysis (DIA) detection efficiencies, but it does include {\tt spuriousness} in the {\tt DIASource} catalog, defining {\tt spuriousness} as {\it ``computed using information from the source and image characterization"}. As discussed in \S~\ref{ssec:docs_oss}, threshold values for {\tt spuriousness} will be provided to generate subsamples of {\tt DIASources} with a given completeness and purity. Recall that {\it spuriousness} represents the probability that a source is astrophysical in origin, given that it was detected -- it cannot be used to derive the probability that an astrophysical source would be detected, given that it exists.

{\bf Summary --} The DPDD does not list any DIA data products that could be used for detection efficiencies or that are directly derived from the fake injection of point sources.

%The {\tt DIASource} catalog table has four parameters that might be scientifically useful for analyses involving detection efficiencies:
%\begin{itemize}
%\item {\tt psLnL [float]} -- {\it Natural log likelihood of the observed data given the point source model.} This represents the probability that a detected source is a point source; detection efficiencies would not apply to non-point sources.
%\item {\tt fpBkgd [float]} $\rm nJy/asec^2$ -- {\it Estimated background at the position (centroid) of the object in the template image.} This will be useful to provide detection efficiencies in difference images as a function of the background at that location.
%\item {\tt fpBkgdErr [float]} $\rm nJy/asec^2$ -- {\it Estimated uncertainty of {\tt fpBkgd}.} Useful in the same way as {\tt fpBkgd}. 
%\item {\tt spuriousness [float]} -- {\it  A measure of spuriousness, computed using information from the source and image characterization, as well as the information on the Telescope and Camera system (e.g., ghost maps, defect maps, etc.).} This is similar to a real/bogus score (\S~\ref{ssec:sci_rb}). As discussed in \S~\ref{ssec:docs_oss}, threshold values for {\tt spuriousness} will be provided to generate subsamples of {\tt DIASources} with a given completeness and purity.
%\end{itemize}

% Regarding the {\tt spuriousness}, the DPDD text further notes that {\it ``The computation of spuriousness will be 'prior free' to the extent possible and not use any information about the astrophysical neighborhood of the source, whether it has been previously observed or not, etc. The intent is to avoid introducing a bias against unusual sources or sources discovered in unusual environments.} The {\tt spuriousness} measure is motivated by OSS-REQ-0351 through 54. In particular, OSS-REQ-0351 states that the spuriousness parameter be assessed by, e.g., {\it ``insertion and recovery of artificial sources"}, and OSS-REQ-0352 states that {\it ``for each visit"}, the completeness and purity of the sample of {\tt DIASources} as a function of a {\tt spuriousness} threshold shall be estimated. 

% Section 3.2 {\it ``Image Characterization Data"} specifies that {\it ``Each processed image .. will record information on the pixel variance ... as well as the per-pixel masks ... These will allow the users to determine the validity and usefulness of each pixel in estimating the flux density recorded in that area of the sky."} But that is more for evaluating uncertainty for analyzes that use pixel fluxes, and not for detection efficiencies in difference images.


% % % % % % % % % % % % % % % % 
\subsection{Data Management Science Pipelines Design}\label{ssec:docs_ldm151}

The Data Management Science Pipelines Design document \citedsp{LDM-151} details the implementation of the requirements set by the SRD, OSS, and DMSR, and how the data products described in the DPDD are generated. \citeds{LDM-151} does not have much to say about detection efficiencies; Section 3, {\it ``Alert Production"}, states that {\it ``In this document we do not address estimation of the selection function for alert generation through the injection of simulated sources. Such a process could be undertaken in batch mode as part of the DRP."} However, \citeds{LDM-151} does make two relevant statements about the {\tt spuriousness} parameter which describe how the real-bogus algorithm will likely {\it ``be based on a trained random forest classifier ... conditioned on the image quality and airmass"} (Section 3.2.4) and that it  {\it ``may use machine learning on other measurements or pixels"} (Section 6.7.2).

{\bf Summary --} \citeds{LDM-151} does not address fake injection -- or any other specific method -- as a means to the {\tt spuriousness} measurements or detection efficiencies.

%Section 3.2.4, {\it ``Difference Imaging"}, states that {\it ``The application of spuriousness algorithms, also known as 'real-bogus', may be applied at this time dependent on whether the number of false positives is less than 50\% of the detected sources. ... The default technique will be based on a trained random forest classifier. It is likely that the training of this classifier will need to be conditioned on the image quality and airmass of the observations."} 

% Section 6.7.2, {\it ``Algorithms"}, states that the {\tt spuriousness} measurement is a {\it ``per-source measure of likelihood the detection is junk (in a difference image)"} that {\it ``may use machine learning on other measurements or pixels"} and {\it ``may be augmented by spuriousness measures that aren't purely per-source"}. Figure 12, a matrix showing the algorithms applied to the different types of measurements (single visit, difference image, etc.) shows that a different implementation or algorithm for {\tt spuriousness} will be used for the Difference Image Measurement compared to the Single Visit, Multi-Coadd, Multi-Epoch, and Forced Measurements.

% Section 5.6.3, {\tt MakeSelectionMaps}, states that this calibration step {\it ``is responsible for producing multi-scale maps that describe LSST's depth and efficiency at detecting different classes of object. The details of what metrics will be mapped, the format and scale of the maps (e.g. hierarchical pixelizations vs. polygons), and the way the metrics will be computed are all unknown".} It also states that this must be extendable to Level 3, but that {\it ``the details of what DM will provide still needs to be clarified to the community"}, and notes that the reprocessing time for fake plants could be prohibitive. However, this referring to the depth and efficiency of detecting static-sky objects in the direct images or deep coadds, not transients/variables in the difference images.


% % % % % % % % % % % % % % % % 
\subsection{Summary of Existing Requirements and Plans}\label{ssec:docs_sum}

The OSS requires that spuriousness be measured for each detected difference image source, and that spuriousness thresholds are defined and supplied to users in order to create subsets of known completeness and purity for a given signal-to-noise ratio (\S~\ref{ssec:docs_oss}). The OSS furthermore specifies that the spuriousness characterization be done {\it ``by insertion and recovery of artificial sources"}, and that these thresholds are specified to be {\it ``interpreted as an average over the entire survey"} (\S~\ref{ssec:docs_oss}). The DMSR specifies that {\it software} for fake injection is a deliverable of the DMS (\S~\ref{ssec:docs_dmsr}).

There is no requirement or plan regarding the provision of a detection efficiency matrix, $\eta(\vv{P})$, or for the provision of the results of fake injection and recovery from which such a matrix could be built by users.


% % % % % % % % % % % % % % % % 
\subsection{Could Detection Efficiencies be Derived from Provided Data Products?}\label{ssec:docs_derDE}

Could the spuriousness parameter $\mathcal{S}$, and the relationship between $\tau_{\mathcal{S}}$ and completeness --- both of which are specified by the OSS to be included in the data products (\S~\ref{ssec:docs_oss}) -- be used to create a full detection efficiency matrix, $\eta(\vv{P})$? 

No. The current OSS requirements are to characterize the relationship between $\tau_{\mathcal{S}}$ and sample completeness {\it only as a function of visit image qualities} (\S~\ref{sec:docs}). As discussed in \S~\ref{sec:intro} and \ref{sec:sci}, most scientific endeavors require $\eta(\vv{P})$ to be known as a function of other parameters such as the underlying surface brightness of the host galaxy (Table \ref{tab:eta_pars}).

To ask the question more explicitly: why couldn't one take all {\tt DIASources}, bin them by the local $r$-band surface brightness in the direct image, calculate the mean spuriousness value $\mathcal{S}$ for each bin, apply the provided relationship between $\tau_{\mathcal{S}}$ and completeness to obtain the average completeness each bin, and use the result as the ``detection efficiency" as a function of local surface brightness? And then repeat these steps for the other parameters, $\vv{P}$, listed in Table \ref{tab:eta_pars}, to build a model of $\eta(\vv{P})$?

Doing so would be incorrect because the relationship between $\tau_{\mathcal{S}}$ and completeness only applies to the bulk sample the includes all values of local surface brightness, and {\it spuriousness} does not necessarily correlate with the local surface brightness in the same way as {\it completeness}.



% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Options For Generating LSST Detection Efficiencies} \label{sec:DE}

In this section we list and discuss options for generating detection efficiencies, but which we mean building a model of completeness (the probabilities that a source is detected, given that it exists) as a function of the parameters listed in Table \ref{tab:eta_pars}: $\eta(\vv{P})$.

We discuss each option in terms of scope, risk, requirements, and science.
% Regarding scope, K-T has mentioned that the computational system is sized for the additional processing of all images with fake sources implanted.

% % % % % % % % % % % % % % % % 
\subsection{Do Not Generate Detection Efficiencies}\label{ssec:DE_no}

{\bf Scope --} No expansion of scope. \\
{\bf Risk --} A moderate risk in that multiple user groups may then need to perform fake injection, leading to redundant reprocessing of the data and a computational strain on the resources. \\
{\bf Requirements --} Does not violate any requirements. \\
{\bf Science --} This option would negatively impact science results based on transient phenomena, one of the four pillars of LSST science. The need for computationally intensive processing would force multiple teams to compete, and might limit the number of individuals or teams who could successfully derive detection efficiencies, and thus limit the scientific applications.

% % % % % % % % % % % % % % % % 
\subsubsection{Make Available the Data on Fake Injected Sources}\label{sssec:DE_no_butmakefakeavail}

The same set of injected point sources that will be required to characterize spuriousness (\S~\ref{ssec:docs_oss}) could also be used to derive detection efficiencies, provided that they sample the full parameter space of $\vv{P}$. In lieu of calculating and providing detection efficiencies, the data for the injected fake sources could be provided so that users may build their own detection efficiency matrices, $\eta(\vv{P})$. For example, a {\tt DIASource}-like catalog for the fake injected point sources that includes both the location and image parameters ($\vv{P}$) listed in Table \ref{tab:eta_pars}, and also the results of DIA and source detection.

{\bf Scope --} Small expansion of scope to make available these fake-source catalogs. \\
{\bf Risk --} No risks. \\
{\bf Requirements --} Does not violate any requirements. \\
{\bf Science --} Allowing users to build detection efficiency matrices would enable science analyses based on transient phenomena.

% % % % % % % % % % % % % % % % 
\subsection{Generate Detection Efficiencies Without Fake Injection}\label{ssec:DE_nofakes}

\textcolor{red}{MLG: I've heard RL say there are other ways to generate detection efficiencies than fake injection, but outside of co-temporal data of superior quality (which will not be available), I'm not sure how to know how many real things are missed as a function of apparent magnitude and other parameters. Maybe RL can fill in this section.}

 
% % % % % % % % % % % % % % % % 
\subsection{Generate Detection Efficiencies via Fake Injection}\label{ssec:DE_fakes}

Here we consider three possible points in the data processing where the fake injection could be performed: during alert production (\S~\ref{sssec:DE_fakes_AP}), on an intermediate timescale between Prompt and DR (\S~\ref{sssec:DE_fakes_int}), and during DR processing (\S~\ref{sssec:DE_fakes_DR}).

\subsubsection{During Alert Production}\label{sssec:DE_fakes_AP}

Inject fake sources into the live data which is processed within 60 seconds of image readout (OTT1). This may seem like an extreme option to propose, but as discussed in \S~\ref{ssec:sci_trans} some previous transient surveys have injected fakes into their real-time pipelines.

With this option, fake sources would be injected {\it on the fly into every new visit image from the telescope processed with DIA} (or into the template image as negatives). This process would be comprised of three steps: (1) identify coordinates where the fakes should be planted, (2) fake injection into the image, and (3) bookkeeping for the fakes to ensure they do not contaminate the Alert Stream or the {\tt DIASource} catalog. Fakes should not be injected at random locations because it is important to sample regions with higher surface brightness and to avoid the locations of known {\tt DIAObjects}. If 1000 fakes are injected into a 3.2 Gp image, and we assume that image has 10000 randomly-distributed true {\tt DIAObjects} in it, then the probability that none of the fakes land on one of the true sources is $0.9968$; but over a full night of 1000 visits, the probability that none of the fakes ever landed on a true source in any image is $0.0437$, and it is most likely ($P=0.2218$) that 3 fakes would have interfered with true sources. 
% from scipy.stats import hypergeom
% import matplotlib.pyplot as plt
% [M,n,N] = [3200000000,10000,1000]
% rv = hypergeom(M,n,N)
% print( rv.pmf([0,1,2,3,4]) )
% [  9.96843454e-01   3.11521588e-03   4.86216368e-06   5.05362508e-09   3.93505558e-12]
% [M,n,N] = [3200000000000,10000000,1000000]
% rv = hypergeom(M,n,N)
% print( rv.pmf([0,1,2,3,4]) )
% [ 0.04367555  0.13880061  0.21497859  0.22180274  0.17274015]

Two of the benefits of fake injection during LSST Alert Production are that (1) it would negate the need for separate re-processing of all fake-infused images, which could increase the total computational budget by up to a factor of $2$, and (2) it could offer real-time feedback on evolution in the survey's completeness or purity, which might be useful --- however, real-time feedback is not a necessary component of the DMS and could be obtained via the spuriousness parameters, as completeness and purity correlate mainly with bulk image properties.

Two of the main drawbacks of planting fakes into "live" data are that (1) only a small number should be planted so as to minimize the risk of interference with real phenomena and (2) the additional steps of simulating, planting, and verifying fakes must be included in the computational budget for Alert Production, which completes within $60$ seconds for every new direct image and is already tightly constrained. 

{\bf Scope --} An expansion of scope in terms of FTE work hours and computational resources. \\
{\bf Risk --} A risk to the DMS by adding three steps to the 60-second processing budget and potentially interfering with the completeness and purity of the Alert Stream. \\
{\bf Requirements --} Does not violate any requirements (and is not necessary to meet any requirements). \\
{\bf Science --} This option would provide scientifically useful detection efficiencies, however, it may compromise science results if it interferes with the completeness and purity of the Alert Stream. As there would be a limit on the number of fakes injected into every image, and restrictions that those fakes be away from most true transients and variables, this method would not provide the {\it best} characterization of the survey's detection efficiencies.


% % % % % % % % % % % % % % % % 
\subsection{On an Intermediate Timescale}\label{sssec:DE_fakes_ing}

As a compromise between injecting fakes during Prompt Processing (above) and during Data Release Processing (below), fakes could be injected and recovered on a intermediate timescale (e.g., daily, weekly, monthly). There would be no need to reprocess {\it every} image, as the goal is to build up a detection efficiency model as a function of parameters like host background, seeing and airmass --- so this pipeline could include only images in the parameter space where additional fakes are required. However, as with the proposed option to do fake injection during alert production, there's no science case, or internal use-case, that requires the detection efficiencies updated in real time.  

{\bf Scope --} An expansion of scope in terms of both FTE and computational resources of the DMS. \\
{\bf Risk --} A risk to the DMS (increasing the amount of processing done in between DRs). \\
{\bf Requirements --} Does not violate any requirements. \\
{\bf Science --} This option would enables rates analyses on the Prompt data products, but these analyses are more likely to be done on the DR data products anyway, so it is unlikely that this option opens the door for any new --- or otherwise inaccessible --- science. 


% % % % % % % % % % % % % % % % 
\subsection{During DR Processing}\label{sssec:DE_fakes_DR}

This option is to incorporate fake injection into DIA processing for the annual Data Release processing. Fake point sources can be injected only in locations where there were no detected {\tt DIASources}, and in all images without increasing the total computational budget by any more than is required to inject the PSFs. As described in Section \ref{sec:sci}, it is likely that fake injection would be done as part of DIA during DR processing anyway, in order to characterize the spuriousness parameter, so this option might only be adding a step to ensure that the fakes are injected in a way that samples the parameter space $\vv{P}$ (Table \ref{tab:eta_pars}) needed to use the fakes for detection efficiencies --- and deriving the detection efficiencies themselves. Then, the same detection efficiencies can be used on the Prompt data products for the following year with the same template images. 

{\bf Scope --} A mild expansion of scope in terms of both FTE and computational resources. \\
{\bf Risk --} No risks. \\
{\bf Requirements --} Does not violate any requirements. \\
{\bf Science --} Enables science on the DR data products, which is the most likely place that they're going to be used. 


% % % % % % % % % % % % % % % % 
\subsection{Summary of Options for Generating Detection Efficiencies}

It would be most scientifically useful -- with only a small increase in scope -- to ensure that the fake injection of point sources used to characterize the {\tt DIASouce} spuriousness parameter fill the parameter space needed for scientific analyses involving detection efficiencies, and to provide the detection efficiency matrix $\eta(\vv{P})$. It would also be scientifically useful to make catalogs of the injected fakes available to users, to enable them to build $\eta(\vv{P})$. In both cases, to incorporate fake injection into DIA processing as part of the annual Data Release processing both achieves the science goals and minimizes scope increase and risk to the DMS.


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Options for Fake Point Source Injection Techniques}\label{sec:opts_fakes}

There are a variety of ways in which fake sources can be simulated and injected into the images, with some options better for transients and some for variable stars. Here we give a precursory discussion of the options available. A full evaluation of which method of fake injection should be used, as well as an analysis of the number of fakes required in order to adequately parameterize the detection efficiency $\eta$ as a function of parameters $\vv{P}$, is left to other work.

% % % % % % % % % % % % % % % % 
\subsection{Simulating New Fake Objects}

This applies to point sources that appear where there was no point source before, e.g., transients (supernovae) and moving objects (assuming they're slow-moving enough not to be trailed, which is a different problem).

{\bf Model PSF ---} A model for the PSF in the image, as a function of location in the focal plane (and any other factors that effect PSF shape, such as the brighter/fatter effect), is used to simulate a point source. 

{\bf Clone-Stamping ---} A nearby star is cut out and rescaled, and used as the simulated point source. One of the main drawbacks of using clone-stamping with LSST images is that incorporating the brighter/fatter effect into the simulation requires either that a star which is both nearby and of a similar brightness be used or that a model component added to the clone star to appropriately change the shape for the simulated brightness. Another drawback of clone-stamping is that very sparse/crowded fields might not have enough nearby/isolated point sources to use.

To decide between model PSFs and clone-stamping will require some testing in order to properly assess their performance and load on the computational resources. However, since knowing the PSF very accurately is something the LSST DMS will already be doing, it seems likely that the Model PSF option should be easier.

{\bf Location ---} For supernovae and other extragalactic transients, they mostly "follow the light" and so should be distributed in an image accordingly. Moving objects would appear at random locations and mostly in open space, but fake sources planted mainly atop galaxies will still satisfy the moving-object use-case of needing a DIA detection efficiencies when their orbits have coincided with static-sky sources.

% % % % % % % % % % % % % % % % 
\subsection{Simulating Variability in Real Objects}\label{ssec:opts_fakes_simvar}

This applies to both simulating variability in real point sources (stars, AGN), and simulating new point sources with variability.

{\bf Adding a Variable Component to Real Objects ---} Simulate a PSF with the desired variable flux component, and add it to the real object's 2D profile. This option is more difficult to incorporate brighter/fatter, but could anyway be useful for small variable flux components.

{\bf Scaling-in-Place ---} Cutout the star, multiply its 2D profile by a scalar in order to make it brighter or fainter, and add it back to the image. This could be modified to account for the brighter/fatter effect by, e.g., convolving with a kernel that both applies the effect and the desired variability, instead of multiplying by a scalar.

{\bf Simulating New Stars ---} In crowded fields, detecting the variable component in a difference image may be more correlated with the apparent magnitude of the star in the template, and it might be difficult to accurately measure the detection efficiency near the detection limit. Explore whether it would be plausible to simulate stars in the reference and the direct image with a flux difference between them so that the calculation of detection efficiencies is not limited to only the well-distinguished stars in a crowded field. However, simulating new stars in both the template and reference adds a new degree of complexity: the location in the template/direct image must account for any DCR correction that's about to happen (or the planting should happen after DCR-correction).

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\bibliography{local,lsst,refs,books,refs_ads}
% \appendix
\end{document}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
%%% Sample Table
% \begin{table}[h]
% \begin{center}
% \begin{footnotesize}
% \caption{caption}
% \label{tab:???}
% \begin{tabular}{lll}
% \hline \hline
% C1 & C2 & C3 \\
% \hline
% V1 & V2 & V3 \\
% \hline
% \end{tabular}
% \end{footnotesize}
% \end{center}
% \end{table}
