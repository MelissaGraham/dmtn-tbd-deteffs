\section{Options Regarding Detection Efficiencies} \label{sec:opts}

The options for DM to participate in generating detection efficiencies, $\eta(\vv{P})$, are listed and discussed in terms of scope, risk, requirements, and science. 

% % % % % % % % % % % % % % % % 
\subsection{Do Nothing}\label{ssec:opts_no}

In this scenario, the data from any fake injection that is done in order to meet the requirement to characterize the spuriousness is not made available, but the science community would have access to the {\it software} for fake injection.

{\bf Scope --} No expansion of scope. \\
{\bf Risk --} A moderate risk in that multiple user groups may then need to perform fake injection, leading to redundant reprocessing of the data and a computational strain on the resources. \\
{\bf Requirements --} Does not violate or fulfill any requirements. \\
{\bf Science --} This option would negatively impact science results based on transient phenomena, one of the four pillars of LSST science. The need for computationally intensive processing would force multiple teams to compete, and might limit the number of individuals or teams who could successfully derive detection efficiencies, and thus limit the scientific applications.

% % % % % % % % % % % % % % % % 
\subsection{Make Available the Fakes Injected for Spuriousness Characterization}\label{ssec:opts_makefakeavail}

In this scenario, the data generated by the injection and recovery artificial sources in order to meet the requirements to characterize the spuriousness parameter is made available so that users may calculate detection efficiencies. For example, a {\tt DIASource}-like catalog for the fake injected point sources, which users could bin by the $\vv{P}$ relevant to their science and generate $\eta(\vv{P})$. Since the current OSS requirements are to characterize the relationship between $\tau_{\mathcal{S}}$ and sample completeness {\it only as a function of visit image qualities} for {\tt DIASources} with SNR$>$5 (\S~\ref{sec:docs}), this scenario does not guarantee that these artificial sources will be adequate for all science use-cases. 

{\bf Scope --} Possible expansion of scope to make available the fake-source catalogs. \\
{\bf Risk --} Minor risk, if the fake sources do not adequately cover $\vv{P}$, for the same reason as in \S~\ref{ssec:opts_no}. \\
{\bf Requirements --} Does not violate or fulfill any requirements. \\
{\bf Science --} Allowing users to build detection efficiency matrices from the same fake sources as are used to characterize spuriousness would enable at least some scientific analyses.

% % % % % % % % % % % % % % % % 
\subsection{Ensure the Fakes Injected for Spuriousness Characterization Meet Science Goals}\label{ssec:opts_ensurefakeP}

This scenario is similar to that in \S~\ref{ssec:opts_makefakeavail}, except the fake sources that are injected and recovered in order to meet the requirements to characterize the spuriousness parameter are scientifically validated to cover the parameters needed for scientific analyses, $\vv{P}$, as listed in Table \ref{tab:eta_pars}.

{\bf Scope --} Minor expansion of scope to validate the artificial sources cover an adequate range of parameter space, $\vv{P}$, and to make available the fake-source catalogs. \\
{\bf Risk --} No risk. \\
{\bf Requirements --} Does not violate or fulfill any requirements. \\
{\bf Science --} Allowing users to build detection efficiency matrices from a scientifically-validated set of artificial sources would enable more scientific analyses.

% % % % % % % % % % % % % % % % 
\subsection{Generate and Provide Detection Efficiencies}\label{ssec:opts_deteffs}

This scenario takes that of \S~\ref{ssec:opts_ensurefakeP} one step further, and has the DMS generate and provide the detection efficiency matrix, $\eta(\vv{P})$, as a scientifically validated and verified data product.

{\bf Scope --} Moderate expansion of scope to generate $\eta(\vv{P})$. \\
{\bf Risk --} No risk. \\
{\bf Requirements --} Does not violate or fulfill any requirements. \\
{\bf Science --} Enables scientific analyses for all that need detection efficiencies.

% % % % % % % % % % % % % % % % 
%\subsection{Generate Detection Efficiencies Without Fake Injection}\label{ssec:opts_nofakes}
%\textcolor{red}{MLG: I've heard RL say there are other ways to generate detection efficiencies than fake injection, but outside of co-temporal data of superior quality (which will not be available), I'm not sure how to know how many real things are missed as a function of apparent magnitude and other parameters. Maybe RL can fill in this section.}

\subsection{Inject Fakes during Prompt or Data Release Processing?}\label{ssec:opts_fakeswhen}

Here is considered three possible points in the data processing where the fake injection could be performed: during Prompt processing (\S~\ref{sssec:opts_fakeswhen_PP}), on an intermediate timescale between Prompt and Data Release processing (\S~\ref{sssec:opts_fakeswhen_int}), and during DR processing (\S~\ref{sssec:opts_fakeswhen_DR}).

\subsubsection{During Prompt Processing}\label{sssec:opts_fakeswhen_PP}

Inject fake sources into the live data which is processed within 60 seconds of image readout ({\tt OTT1}). With this option, fake sources would be injected {\it on the fly into every new visit image from the telescope processed with DIA} (or into the template image as negatives). This may seem like an extreme option to propose, but as discussed in \S~\ref{ssec:sci_trans} some previous transient surveys have injected fakes into their real-time pipelines, so we consider it here as well. 

{\bf Scientific Motivation for Prompt Fakes --} Surveys that plant artificial sources into live data processing typically use realistic light curves that represent their target population (e.g., color, duration, and location), and inject the fakes into sequential images in order to simulate real transients. The objective of this level of real-time injection is usually not just to characterize the detection efficiency, but also biases in the survey's classification algorithms and/or follow-up programs. Simulating fake sources that represent {\it real transient light-curves} in sequential images and in different filters in a realistic way is {\it not} being proposed here. Furthermore, most of the scientific analyses that require detection efficiencies, such as occurrence rates and population studies, would be done with the DIA products from a data release, and not the prompt products. A continually-updated detection efficiency matrix, $\eta(\vv{P})$, that incorporates data from fakes injected during Prompt processing does not have a strong scientific motivation.

{\bf Interference with Astrophysical Sources -- } In this scenario, fake sources would be planted into new images in a manner that samples the range of parameters for $\eta(\vv{P})$. This process would be comprised of three steps: (1) identify coordinates where the fakes should be planted, (2) fake injection into the image, and (3) bookkeeping for the fakes to ensure they do not contaminate the Alert Stream or the {\tt DIASource} catalog. Fakes should not be injected at random locations because it is important to sample regions with higher surface brightness and to avoid the locations of known {\tt DIAObjects}. If 1000 fakes are  assigned random locations and injected into a 3.2 Gp image, and we assume that image has 10000 (randomly-distributed) true sources in it, then the probability that none of the fakes are coincident with one of the true sources is $0.9968$. However, over a full night of 1000 visits, the probability that none of the fakes ever landed on a true source in any image is $0.0437$, and it is most likely ($P=0.2218$) that 3 fakes would have interfered with true sources. 
% from scipy.stats import hypergeom
% import matplotlib.pyplot as plt
% [M,n,N] = [3200000000,10000,1000]
% rv = hypergeom(M,n,N)
% print( rv.pmf([0,1,2,3,4]) )
% [  9.96843454e-01   3.11521588e-03   4.86216368e-06   5.05362508e-09   3.93505558e-12]
% [M,n,N] = [3200000000000,10000000,1000000]
% rv = hypergeom(M,n,N)
% print( rv.pmf([0,1,2,3,4]) )
% [ 0.04367555  0.13880061  0.21497859  0.22180274  0.17274015]

{\bf Benefits and Drawbacks of Prompt Fakes from a DM Perspective -- } Two of the benefits (to LSST DM) of fake injection during Prompt processing are that (1) it would negate the need for separate re-processing of all fake-infused images, which could increase the total computational budget by up to a factor of $2$, and (2) it could offer real-time feedback on evolution in the survey's completeness or purity, which might be useful --- however, real-time feedback is not a necessary component of the DMS and could be obtained via the spuriousness parameters, as completeness and purity correlate mainly with bulk image properties. Two of the main drawbacks of planting fakes into "live" data are that (1) only a small number should be planted so as to minimize the risk of interference with real phenomena and (2) the additional steps of simulating, planting, and verifying fakes must be included in the computational budget for Prompt processing, which completes within $60$ seconds for every new direct image and is already tightly constrained. 

{\bf Scope --} An expansion of scope in terms of FTE work hours and computational resources. \\
{\bf Risk --} A risk to the DMS by adding three steps to the 60-second processing budget and potentially interfering with the completeness and purity of {\tt DIASources}. \\
{\bf Requirements --} Does not violate any requirements (and is not necessary to meet any requirements). \\
{\bf Science --} This option would provide scientifically useful detection efficiencies, however, it may compromise science results if it interferes with the completeness and purity of {\tt DIASources}. As there would be a limit on the number of fakes injected into every image, and restrictions that those fakes be away from most true transients and variables, this method would not provide the {\it best} characterization of the survey's detection efficiencies.

% % % % % % % % % % % % % % % % 
\subsubsection{On an Intermediate Timescale}\label{sssec:opts_fakeswhen_int}

As a compromise between injecting fakes during Prompt Processing (above) and during Data Release Processing (below), fakes could be injected and recovered on a intermediate timescale (e.g., daily, weekly, monthly). There would be no need to reprocess {\it every} image because the goal is to build up a detection efficiency model as a function of parameters like host background, seeing and airmass. This pipeline could include only images in the parameter space where additional fakes are required. However, as with the proposed option to do fake injection during Prompt processing, there is no science case (or internal use-case) that requires the detection efficiencies updated in real time.  

{\bf Scope --} An expansion of scope in terms of both FTE and computational resources of the DMS. \\
{\bf Risk --} A risk to the DMS (increasing the amount of processing done in between DRs). \\
{\bf Requirements --} Does not violate any requirements. \\
{\bf Science --} This option would enables rates analyses on the Prompt data products, but these analyses are more likely to be done on the DR data products anyway, so it is unlikely that this option opens the door for any new --- or otherwise inaccessible --- science. 

% % % % % % % % % % % % % % % % 
\subsubsection{During Data Release Processing}\label{sssec:opts_fakeswhen_DR}

The benefits of implanting artificial sources into images during the DIA which occurs as a part of the annual DR processing is that fakes can be injected (1) only in locations where there were no detected {\tt DIASources} and (2) in all images without increasing the total computational budget by any more than is required to inject the PSFs. As described in Section \ref{sec:docs}, it is likely that fake injection would be done as part of DIA during DR processing anyway, in order to characterize the spuriousness parameter. This option is only be adding a step to ensure that the fakes are injected in a way that samples the parameter space $\vv{P}$ (Table \ref{tab:eta_pars}), as needed to use the fakes for detection efficiencies. These DR-derived detection efficiencies could be used on the Prompt data products for the following year. 

{\bf Scope --} A mild expansion of scope in terms of FTE, but potentially not in terms of computational resources. \\
{\bf Risk --} No risks. \\
{\bf Requirements --} Does not violate any requirements. \\
{\bf Science --} Enables science with both the DR and Prompt data products. 


% % % % % % % % % % % % % % % % 
\subsection{Could Detection Efficiencies be Derived from Provided Data Products?}\label{ssec:docs_derDE}

Could the spuriousness parameter $\mathcal{S}$, and the relationship between $\tau_{\mathcal{S}}$ and completeness --- both of which are specified by the OSS to be included in the data products (\S~\ref{ssec:docs_oss}) -- be used to create a full detection efficiency matrix, $\eta(\vv{P})$? In other words, could the following process be used? (1) bin the {\tt DIASources} by $\vv{P}$; (2) calculate the mean spuriousness as a function of apparent magnitude in the bin ($\bar{\mathcal{S}}(m)$); (3) use the established relationship between $\tau_{\mathcal{S}}(m)$ and completeness (\S~\ref{ssec:docs_oss}) to derive $\eta(\vv{P})$.

No. First, the relation between $\tau_{\mathcal{S}}$ and completeness (\S~\ref{ssec:docs_oss}) provides the completeness for all sources with $\mathcal{S}>\tau_{\mathcal{S}}$, whereas the scientific analyses will want the completeness in discrete bins. Second, this relation has already marginalized over parameters $\vv{P}$, and to attempt to "reverse-engineer" them will not be accurate. Third, using the {\tt DIASources} to derive $\eta(\vv{P})$ will lead to a bias, since only {\it already detected} objects are contributing to the detection efficiency. 
% the current OSS requirements are to characterize the relationship between $\tau_{\mathcal{S}}$ and sample completeness {\it only as a function of visit image qualities} (\S~\ref{sec:docs}). 


% % % % % % % % % % % % % % % % 
\subsection{Summary of Options}\label{ssec:opts_sum}

It would be scientifically useful -- with only a potential small increase in scope, if any -- to ensure that the artificial sources implanted to characterize the {\tt DIASouce} spuriousness parameter sample the parameter space needed for scientific analyses involving detection efficiencies, $\vv{P}$ (e.g., Table \ref{tab:eta_pars}), and to make the data from the injection and recovery of fake sources available to users so that they can build detection efficiency matrices $\eta(\vv{P})$. It would be even more useful to provide $\eta(\vv{P})$ as a scientifically validated data product. For both scenarios, doing the fake injection during the DIA which occurs as a prt of the annual Data Release processing both achieves the science goals and minimizes scope increase and risk to the DMS.
